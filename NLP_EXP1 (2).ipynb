{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0Y/61fXsv2OgbL6BNzdG+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"s5vLR3tg1LUA","executionInfo":{"status":"ok","timestamp":1753686530367,"user_tz":-330,"elapsed":2353,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}}},"outputs":[],"source":["import nltk\n","import string\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ek04SErS1mB_","executionInfo":{"status":"ok","timestamp":1753686560506,"user_tz":-330,"elapsed":217,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}},"outputId":"48c6e37d-7908-420d-9387-e65c9a064c5c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["documents = [\n","    \"Machine learning is transforming the world.\",\n","    \"Natural Language Processing is a part of AI.\",\n","    \"TF-IDF and Bag-of-Words are used for text feature extraction.\",\n","    \"Text preprocessing is essential in NLP tasks.\"\n","]"],"metadata":{"id":"iaHLs8dO1oSl","executionInfo":{"status":"ok","timestamp":1753686562612,"user_tz":-330,"elapsed":3,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def preprocess(text):\n","    lemmatizer = WordNetLemmatizer()\n","    stop_words = set(stopwords.words('english'))\n","\n","    tokens = nltk.word_tokenize(text.lower())\n","    tokens = [word for word in tokens if word.isalpha()]\n","    tokens = [word for word in tokens if word not in stop_words]\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","    return \" \".join(tokens)"],"metadata":{"id":"6N5IQyJv1sYG","executionInfo":{"status":"ok","timestamp":1753686565276,"user_tz":-330,"elapsed":4,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["cleaned_docs = [preprocess(doc) for doc in documents]"],"metadata":{"id":"7KVVIb_f1ywX","executionInfo":{"status":"ok","timestamp":1753686570618,"user_tz":-330,"elapsed":3475,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["bow_vectorizer = CountVectorizer()\n","bow_matrix = bow_vectorizer.fit_transform(cleaned_docs)"],"metadata":{"id":"SSOOgSF712C1","executionInfo":{"status":"ok","timestamp":1753686582887,"user_tz":-330,"elapsed":13,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(\"\\nðŸ”¹ Bag-of-Words Vocabulary:\")\n","print(bow_vectorizer.get_feature_names_out())\n","\n","print(\"\\nðŸ”¹ BoW Feature Matrix:\")\n","print(bow_matrix.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"51u72BbW15Iu","executionInfo":{"status":"ok","timestamp":1753686584357,"user_tz":-330,"elapsed":13,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}},"outputId":"2c44f6e8-d625-4412-c568-9152341abb85"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ Bag-of-Words Vocabulary:\n","['ai' 'essential' 'extraction' 'feature' 'language' 'learning' 'machine'\n"," 'natural' 'nlp' 'part' 'preprocessing' 'processing' 'task' 'text'\n"," 'transforming' 'used' 'world']\n","\n","ðŸ”¹ BoW Feature Matrix:\n","[[0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1]\n"," [1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0]\n"," [0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0]\n"," [0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0]]\n"]}]},{"cell_type":"code","source":["tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_docs)"],"metadata":{"id":"KRo7Cyp917yX","executionInfo":{"status":"ok","timestamp":1753686586780,"user_tz":-330,"elapsed":26,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(\"\\nðŸ”¹ TF-IDF Vocabulary:\")\n","print(tfidf_vectorizer.get_feature_names_out())\n","\n","print(\"\\nðŸ”¹ TF-IDF Feature Matrix:\")\n","print(tfidf_matrix.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-WUykCJ1-Fu","executionInfo":{"status":"ok","timestamp":1753686587963,"user_tz":-330,"elapsed":7,"user":{"displayName":"TE_CSE_38_Harshvardhan Patil","userId":"00282815489149707913"}},"outputId":"15a263f1-df18-41cf-fbc3-6e1b804fbd54"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ðŸ”¹ TF-IDF Vocabulary:\n","['ai' 'essential' 'extraction' 'feature' 'language' 'learning' 'machine'\n"," 'natural' 'nlp' 'part' 'preprocessing' 'processing' 'task' 'text'\n"," 'transforming' 'used' 'world']\n","\n","ðŸ”¹ TF-IDF Feature Matrix:\n","[[0.         0.         0.         0.         0.         0.5\n","  0.5        0.         0.         0.         0.         0.\n","  0.         0.         0.5        0.         0.5       ]\n"," [0.4472136  0.         0.         0.         0.4472136  0.\n","  0.         0.4472136  0.         0.4472136  0.         0.4472136\n","  0.         0.         0.         0.         0.        ]\n"," [0.         0.         0.52547275 0.52547275 0.         0.\n","  0.         0.         0.         0.         0.         0.\n","  0.         0.41428875 0.         0.52547275 0.        ]\n"," [0.         0.46516193 0.         0.         0.         0.\n","  0.         0.         0.46516193 0.         0.46516193 0.\n","  0.46516193 0.36673901 0.         0.         0.        ]]\n"]}]}]}